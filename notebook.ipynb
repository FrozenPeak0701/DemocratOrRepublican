{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Tbrya1y6HUK1lSa3nRmzmtRw37EwDUw2","timestamp":1677391687364}],"authorship_tag":"ABX9TyPBgcojxIWRJ6chhgf1ptfA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","pd.options.mode.chained_assignment = None  # default='warn'\n","data=pd.read_csv(\"AAG89Dit.csv\")\n","target_label = 'POLAFF'\n","data.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zCq0-AfyVJb8","executionInfo":{"status":"ok","timestamp":1677444754843,"user_tz":300,"elapsed":4728,"user":{"displayName":"FrozenPeak","userId":"16767934579065722113"}},"outputId":"9f8c316f-2947-4981-8aca-c4445aa12be0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (13,15,16,18,32,34,36,37,41,45,46,55,71,83,84,86,87,90,91,92,96,98,100,101,103,104,105,106,107,108,109) have mixed types.Specify dtype option on import or set low_memory=False.\n","  exec(code_obj, self.user_global_ns, self.user_ns)\n"]},{"output_type":"execute_result","data":{"text/plain":["(309119, 111)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["empty = []\n","for i in range(data.shape[0]):\n","  if str(data[target_label][i]).isspace() or float(data[target_label][i])==8. or float(data[target_label][i])==9. or float(data[target_label][i])==2.:\n","      empty.append(i)\n","# empty"],"metadata":{"id":"6tGtRmZlVR-N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data=data.drop(empty).reset_index(drop=True)\n","data[target_label]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r29fbzPCpOAs","executionInfo":{"status":"ok","timestamp":1677447593923,"user_tz":300,"elapsed":172,"user":{"displayName":"FrozenPeak","userId":"16767934579065722113"}},"outputId":"95fd5e20-1757-4782-f202-010d4c9230fa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0        3.0\n","1        3.0\n","2        3.0\n","3        3.0\n","4        3.0\n","        ... \n","42170      3\n","42171      3\n","42172      3\n","42173      3\n","42174      1\n","Name: POLAFF, Length: 42175, dtype: object"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"XhNUJL7V9MCf","executionInfo":{"status":"ok","timestamp":1677444757275,"user_tz":300,"elapsed":6,"user":{"displayName":"FrozenPeak","userId":"16767934579065722113"}},"outputId":"ec507bcd-698b-4474-b9b1-3c1f0244ba93"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       CASEID  YYYYMM  YYYYQ  YYYY    ID IDPREV  DATEPR     ICS     ICC  \\\n","0       28064  198006  19802  1980     1                   2.70    2.70   \n","1       28065  198006  19802  1980     2                  91.51   78.39   \n","2       28067  198006  19802  1980     4                  47.11   78.39   \n","3       28068  198006  19802  1980     5                  17.50   40.54   \n","4       28069  198006  19802  1980     6                  47.11   78.39   \n","...       ...     ...    ...   ...   ...    ...     ...     ...     ...   \n","61965  309115  202301  20231  2023  2096   1049  202207   76.01   77.69   \n","61966  309116  202301  20231  2023  2097   1144  202207  120.42  153.38   \n","61967  309117  202301  20231  2023  2098   1096  202207   31.60   39.84   \n","61968  309118  202301  20231  2023  2099   1121  202207   46.41   77.69   \n","61969  309119  202301  20231  2023  2100   1122  202207   16.80   39.84   \n","\n","         ICE  ...  GAS1PX1  GAS1PX2  GAS1   PINC  PINC2   PJOB   PSSA PCRY  \\\n","0       2.70  ...                                                            \n","1      99.94  ...                                                            \n","2      27.01  ...                                                            \n","3       2.70  ...                                                            \n","4      27.01  ...                                                            \n","...      ...  ...      ...      ...   ...    ...    ...    ...    ...  ...   \n","61965  74.93  ...        1       25    25   80.0    0.0   20.0   10.0    1   \n","61966  99.24  ...        3              0   95.0   95.0   20.0   80.0    3   \n","61967  26.31  ...        3              0    0.0   70.0    0.0  100.0    3   \n","61968  26.31  ...        3              0   50.0  100.0    5.0   60.0    3   \n","61969   2.00  ...        3              0   70.0    0.0    0.0  100.0    1   \n","\n","        PSTK    WT  \n","0             2.65  \n","1             1.77  \n","2             1.32  \n","3             0.00  \n","4             0.88  \n","...      ...   ...  \n","61965   90.0  1.00  \n","61966   60.0  1.25  \n","61967   50.0  0.50  \n","61968   50.0  1.00  \n","61969   50.0  1.25  \n","\n","[61970 rows x 111 columns]"],"text/html":["\n","  <div id=\"df-e97dd794-4916-4eb0-b4e0-4521de149fc9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CASEID</th>\n","      <th>YYYYMM</th>\n","      <th>YYYYQ</th>\n","      <th>YYYY</th>\n","      <th>ID</th>\n","      <th>IDPREV</th>\n","      <th>DATEPR</th>\n","      <th>ICS</th>\n","      <th>ICC</th>\n","      <th>ICE</th>\n","      <th>...</th>\n","      <th>GAS1PX1</th>\n","      <th>GAS1PX2</th>\n","      <th>GAS1</th>\n","      <th>PINC</th>\n","      <th>PINC2</th>\n","      <th>PJOB</th>\n","      <th>PSSA</th>\n","      <th>PCRY</th>\n","      <th>PSTK</th>\n","      <th>WT</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>28064</td>\n","      <td>198006</td>\n","      <td>19802</td>\n","      <td>1980</td>\n","      <td>1</td>\n","      <td></td>\n","      <td></td>\n","      <td>2.70</td>\n","      <td>2.70</td>\n","      <td>2.70</td>\n","      <td>...</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td>2.65</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>28065</td>\n","      <td>198006</td>\n","      <td>19802</td>\n","      <td>1980</td>\n","      <td>2</td>\n","      <td></td>\n","      <td></td>\n","      <td>91.51</td>\n","      <td>78.39</td>\n","      <td>99.94</td>\n","      <td>...</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td>1.77</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>28067</td>\n","      <td>198006</td>\n","      <td>19802</td>\n","      <td>1980</td>\n","      <td>4</td>\n","      <td></td>\n","      <td></td>\n","      <td>47.11</td>\n","      <td>78.39</td>\n","      <td>27.01</td>\n","      <td>...</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td>1.32</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>28068</td>\n","      <td>198006</td>\n","      <td>19802</td>\n","      <td>1980</td>\n","      <td>5</td>\n","      <td></td>\n","      <td></td>\n","      <td>17.50</td>\n","      <td>40.54</td>\n","      <td>2.70</td>\n","      <td>...</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>28069</td>\n","      <td>198006</td>\n","      <td>19802</td>\n","      <td>1980</td>\n","      <td>6</td>\n","      <td></td>\n","      <td></td>\n","      <td>47.11</td>\n","      <td>78.39</td>\n","      <td>27.01</td>\n","      <td>...</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td>0.88</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>61965</th>\n","      <td>309115</td>\n","      <td>202301</td>\n","      <td>20231</td>\n","      <td>2023</td>\n","      <td>2096</td>\n","      <td>1049</td>\n","      <td>202207</td>\n","      <td>76.01</td>\n","      <td>77.69</td>\n","      <td>74.93</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>25</td>\n","      <td>25</td>\n","      <td>80.0</td>\n","      <td>0.0</td>\n","      <td>20.0</td>\n","      <td>10.0</td>\n","      <td>1</td>\n","      <td>90.0</td>\n","      <td>1.00</td>\n","    </tr>\n","    <tr>\n","      <th>61966</th>\n","      <td>309116</td>\n","      <td>202301</td>\n","      <td>20231</td>\n","      <td>2023</td>\n","      <td>2097</td>\n","      <td>1144</td>\n","      <td>202207</td>\n","      <td>120.42</td>\n","      <td>153.38</td>\n","      <td>99.24</td>\n","      <td>...</td>\n","      <td>3</td>\n","      <td></td>\n","      <td>0</td>\n","      <td>95.0</td>\n","      <td>95.0</td>\n","      <td>20.0</td>\n","      <td>80.0</td>\n","      <td>3</td>\n","      <td>60.0</td>\n","      <td>1.25</td>\n","    </tr>\n","    <tr>\n","      <th>61967</th>\n","      <td>309117</td>\n","      <td>202301</td>\n","      <td>20231</td>\n","      <td>2023</td>\n","      <td>2098</td>\n","      <td>1096</td>\n","      <td>202207</td>\n","      <td>31.60</td>\n","      <td>39.84</td>\n","      <td>26.31</td>\n","      <td>...</td>\n","      <td>3</td>\n","      <td></td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>70.0</td>\n","      <td>0.0</td>\n","      <td>100.0</td>\n","      <td>3</td>\n","      <td>50.0</td>\n","      <td>0.50</td>\n","    </tr>\n","    <tr>\n","      <th>61968</th>\n","      <td>309118</td>\n","      <td>202301</td>\n","      <td>20231</td>\n","      <td>2023</td>\n","      <td>2099</td>\n","      <td>1121</td>\n","      <td>202207</td>\n","      <td>46.41</td>\n","      <td>77.69</td>\n","      <td>26.31</td>\n","      <td>...</td>\n","      <td>3</td>\n","      <td></td>\n","      <td>0</td>\n","      <td>50.0</td>\n","      <td>100.0</td>\n","      <td>5.0</td>\n","      <td>60.0</td>\n","      <td>3</td>\n","      <td>50.0</td>\n","      <td>1.00</td>\n","    </tr>\n","    <tr>\n","      <th>61969</th>\n","      <td>309119</td>\n","      <td>202301</td>\n","      <td>20231</td>\n","      <td>2023</td>\n","      <td>2100</td>\n","      <td>1122</td>\n","      <td>202207</td>\n","      <td>16.80</td>\n","      <td>39.84</td>\n","      <td>2.00</td>\n","      <td>...</td>\n","      <td>3</td>\n","      <td></td>\n","      <td>0</td>\n","      <td>70.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>100.0</td>\n","      <td>1</td>\n","      <td>50.0</td>\n","      <td>1.25</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>61970 rows × 111 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e97dd794-4916-4eb0-b4e0-4521de149fc9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e97dd794-4916-4eb0-b4e0-4521de149fc9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e97dd794-4916-4eb0-b4e0-4521de149fc9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["for column in data.columns:\n","  for i in range(data.shape[0]):\n","    if str(data[column][i]).isspace():\n","        data[column][i] = 0"],"metadata":{"id":"qRS4lYCX8UL5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for column in data.columns:\n","  for i in range(data.shape[0]):\n","    if type(data[column][i])==str:\n","      data[column][i] = float(data[column][i])"],"metadata":{"id":"Yi2zDVlqImcq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import torch\n","from torch import nn\n","\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(110, 25),\n","            nn.ReLU(),\n","            nn.Linear(25, 5),\n","            nn.ReLU(),\n","            nn.Linear(5, 2),\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits"],"metadata":{"id":"6QpZ2U9fq-vv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using {device} device\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pp55m648uJ_6","executionInfo":{"status":"ok","timestamp":1677448014972,"user_tz":300,"elapsed":194,"user":{"displayName":"FrozenPeak","userId":"16767934579065722113"}},"outputId":"8f44d980-3445-4094-c9e7-2206a70e03a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cpu device\n"]}]},{"cell_type":"code","source":["model = NeuralNetwork().to(device)\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5lz0wyoGtSDi","executionInfo":{"status":"ok","timestamp":1677448016428,"user_tz":300,"elapsed":124,"user":{"displayName":"FrozenPeak","userId":"16767934579065722113"}},"outputId":"d58b3025-42e4-47fb-b2f6-d398c7cfe92c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=110, out_features=25, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=25, out_features=5, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=5, out_features=2, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"code","source":["print(f\"Model structure: {model}\\n\\n\")\n","\n","for name, param in model.named_parameters():\n","    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HcVHHKwfuDqC","executionInfo":{"status":"ok","timestamp":1677448017434,"user_tz":300,"elapsed":3,"user":{"displayName":"FrozenPeak","userId":"16767934579065722113"}},"outputId":"918c1c3a-7894-4994-f515-62908d1e830b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model structure: NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=110, out_features=25, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=25, out_features=5, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=5, out_features=2, bias=True)\n","  )\n",")\n","\n","\n","Layer: linear_relu_stack.0.weight | Size: torch.Size([25, 110]) | Values : tensor([[-3.8040e-03,  5.8287e-02,  3.1391e-02,  4.7080e-03, -7.1674e-02,\n","          8.8282e-02,  8.4743e-02, -5.2455e-05, -3.9049e-02, -8.1863e-02,\n","         -3.5134e-02,  6.0836e-02, -2.7474e-02,  5.6232e-02,  1.3672e-03,\n","         -6.9897e-03, -2.1360e-02, -5.9138e-02,  4.3404e-02,  2.2178e-03,\n","         -7.0990e-02,  9.3568e-02, -5.7862e-02, -6.5968e-02,  6.6091e-02,\n","         -4.6834e-02,  9.2972e-04,  2.8208e-02,  6.4699e-02,  6.0635e-02,\n","          1.0009e-02, -7.2941e-02, -6.0110e-03,  2.5828e-02, -9.1942e-02,\n","          7.6740e-02,  1.0081e-03,  3.6895e-02,  1.9192e-03, -1.9255e-02,\n","          8.7313e-02, -3.8316e-02,  4.2131e-02, -6.5567e-04, -5.3342e-02,\n","         -2.9962e-02,  2.2689e-02, -1.9771e-02, -7.3682e-03,  6.9934e-02,\n","          2.5411e-02, -7.1993e-02,  9.3816e-02, -8.8788e-02, -8.6656e-02,\n","          6.2230e-02, -1.9437e-02, -4.6680e-02, -2.2612e-02,  2.9039e-02,\n","         -4.2008e-02, -5.6934e-02,  7.1122e-02, -7.6129e-03,  4.2039e-02,\n","          6.1487e-02, -1.4018e-02, -1.9138e-02, -3.8908e-02,  2.5895e-03,\n","         -1.4109e-02, -3.9251e-02,  6.3093e-02, -6.8394e-02,  7.8719e-02,\n","         -1.5517e-02, -1.9022e-02,  5.7301e-02, -2.2106e-02, -5.8156e-02,\n","         -2.5856e-02, -5.7683e-02, -5.7798e-02, -9.4954e-03,  8.2585e-02,\n","          9.4189e-02,  2.8628e-02, -8.0634e-02, -8.3973e-02,  5.3906e-03,\n","          2.2306e-02, -3.0641e-03,  8.6761e-02, -1.4459e-02, -3.6871e-02,\n","         -4.0905e-02, -3.2175e-02,  5.6008e-02, -6.9274e-02, -4.8564e-02,\n","         -6.0556e-02, -8.7410e-03,  4.4375e-02, -7.7270e-03, -6.7195e-02,\n","         -3.1352e-02, -9.3800e-02,  8.1578e-02, -1.7676e-02,  2.9291e-03],\n","        [-8.2758e-02,  1.7162e-02,  1.0218e-02,  3.1015e-02,  7.0096e-02,\n","          4.5362e-02, -6.2339e-02,  3.0285e-04,  5.1234e-02,  9.0909e-03,\n","          4.2741e-02,  1.5519e-02,  6.6046e-03,  3.7447e-02, -1.6130e-02,\n","         -5.7868e-02,  6.7854e-02, -7.3280e-02,  4.3282e-02,  7.4086e-04,\n","         -2.0657e-04,  6.8963e-02,  4.5208e-02,  5.7053e-02, -6.4703e-02,\n","          1.7169e-02, -3.5482e-02,  7.2354e-02,  6.6334e-02,  4.1430e-02,\n","          9.5253e-02,  1.3311e-02, -1.9216e-02,  3.7486e-02,  6.3832e-02,\n","          4.0411e-02, -6.2955e-02, -4.8879e-02, -1.9655e-02, -7.6409e-02,\n","          3.2513e-02,  7.4168e-02,  8.5286e-02, -9.0492e-02, -3.3560e-02,\n","          2.0395e-02, -3.6439e-02,  6.7866e-02, -2.8042e-02,  4.9523e-02,\n","          3.0257e-02, -3.3963e-02,  9.4319e-03, -5.1786e-02,  3.5364e-03,\n","          6.6951e-02, -3.8838e-02, -5.1082e-04,  2.6782e-02, -3.3694e-02,\n","          8.1176e-02,  6.8243e-03, -6.5469e-02, -4.5162e-02, -4.7979e-02,\n","          3.7950e-03, -6.9224e-02, -6.6900e-02,  1.0881e-02, -4.7805e-02,\n","         -2.3387e-02, -3.1682e-03,  9.0783e-03,  3.5201e-02, -2.9075e-02,\n","         -3.9331e-02, -3.1462e-02,  8.8319e-02, -5.4150e-02,  6.0128e-03,\n","         -5.9803e-02,  9.4453e-06,  4.8638e-02,  1.4721e-02, -7.0960e-02,\n","          4.2377e-02,  2.5616e-02,  8.0614e-03, -5.0152e-02, -4.7753e-02,\n","          5.1346e-02, -5.8427e-02,  8.2832e-02, -4.0585e-02,  2.9237e-02,\n","          3.8972e-02,  9.2117e-02,  1.4865e-02,  5.3184e-02,  2.9971e-03,\n","         -3.3580e-02,  3.5887e-03,  8.8836e-02, -5.4621e-02, -4.3892e-02,\n","          3.4341e-02,  1.9793e-02,  3.7585e-02,  2.4651e-02, -5.5278e-02]],\n","       grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.0.bias | Size: torch.Size([25]) | Values : tensor([ 0.0045, -0.0302], grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.2.weight | Size: torch.Size([5, 25]) | Values : tensor([[-0.1724, -0.0552, -0.0867,  0.1030, -0.0842,  0.0966,  0.1723, -0.1715,\n","          0.0763, -0.1408, -0.1062, -0.0610, -0.0888,  0.1331, -0.1952,  0.1971,\n","          0.0818, -0.0950,  0.0369,  0.0851,  0.1693, -0.1357,  0.0876,  0.1438,\n","         -0.0675],\n","        [-0.0883,  0.0041,  0.0566,  0.0281, -0.1726, -0.0614,  0.1809,  0.0920,\n","         -0.1388,  0.1362, -0.1830, -0.1408, -0.1158,  0.1677, -0.0508, -0.0749,\n","          0.0300,  0.1242,  0.1235, -0.0441, -0.0979,  0.0461, -0.0003,  0.0450,\n","          0.1750]], grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.2.bias | Size: torch.Size([5]) | Values : tensor([ 0.1129, -0.1454], grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.4.weight | Size: torch.Size([2, 5]) | Values : tensor([[-0.1043,  0.0332,  0.4066, -0.0302, -0.2676],\n","        [ 0.3186, -0.3010, -0.2421,  0.1282,  0.2453]],\n","       grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.4.bias | Size: torch.Size([2]) | Values : tensor([0.3772, 0.0920], grad_fn=<SliceBackward0>) \n","\n"]}]},{"cell_type":"code","source":["def train_loop(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset)\n","    for batch, (X, y) in enumerate(dataloader):\n","        # Compute prediction and loss\n","        pred = model(X)\n","        loss = loss_fn(pred, y)\n","\n","        # Backpropagation\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch % 100 == 0:\n","            loss, current = loss.item(), (batch + 1) * len(X)\n","            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n","\n","\n","def test_loop(dataloader, model, loss_fn):\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    test_loss, correct = 0, 0\n","\n","    with torch.no_grad():\n","        for X, y in dataloader:\n","            pred = model(X)\n","            test_loss += loss_fn(pred, y).item()\n","            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","\n","    test_loss /= num_batches\n","    correct /= size\n","    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"],"metadata":{"id":"CGuu-G3IvrdH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","import os\n","from torchvision.transforms import ToTensor, Lambda\n","\n","training_data = data[0:40000:]\n","testing_data = data[40000:]\n","\n","training_data_results = training_data[target_label]\n","# for i in range(30000):\n","#   nlist = [0,0,0]\n","#   nlist[training_data_results[i]-1] = 1\n","testing_data_results = testing_data[target_label]\n","training_data = training_data.drop([target_label,], axis=1)\n","testing_data = testing_data.drop([target_label,], axis=1)   #.to_numpy()\n","\n","\n","class CustomImageDataset(Dataset):\n","    def __init__(self, data, label, target_transform=None):\n","        self.labels = label\n","        self.data = data\n","        self.target_transform = target_transform\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        itlabel = self.labels.iloc[idx]-1\n","        if itlabel==2:\n","          itlabel=1\n","        itdata = self.data.iloc[:,idx]\n","        itdata = torch.tensor(itdata)\n","        if self.target_transform:\n","          itlabel = self.target_transform(np.int64(itlabel))\n","        return itdata, itlabel\n","\n","# actual_training_data = [(training_data[i:i+1,].T, training_data_results.iloc[i]) for i in range(training_data.shape[0])]\n","# actual_testing_data = [(testing_data[i:i+1,].T, testing_data_results.iloc[i]) for i in range(testing_data.shape[0])]\n","\n","target_transform = Lambda(lambda y: torch.zeros(\n","    2, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))\n","\n","actual_training_data=CustomImageDataset(training_data.T,training_data_results,target_transform)   # one-hot encoding\n","actual_testing_data=CustomImageDataset(testing_data.T,testing_data_results)\n","\n","learning_rate = 1e-4\n","batch_size = 64\n","epochs = 5\n","\n","train_dataloader = DataLoader(actual_training_data, batch_size=batch_size, shuffle=True)\n","test_dataloader = DataLoader(actual_testing_data, batch_size=batch_size, shuffle=True)\n","\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","\n","for t in range(epochs):\n","    print(f\"Epoch {t+1}\\n-------------------------------\")\n","    train_loop(train_dataloader, model, loss_fn, optimizer)\n","    test_loop(test_dataloader, model, loss_fn)\n","print(\"Done!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T5GKuR20uvT5","executionInfo":{"status":"ok","timestamp":1677448111034,"user_tz":300,"elapsed":91548,"user":{"displayName":"FrozenPeak","userId":"16767934579065722113"}},"outputId":"e0151a07-9b44-42cf-c803-dd92892bc2e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","-------------------------------\n","loss: 242865.062500  [   64/40000]\n","loss: 0.774912  [ 6464/40000]\n","loss: 0.700327  [12864/40000]\n","loss: 0.714860  [19264/40000]\n","loss: 0.726518  [25664/40000]\n","loss: 0.689062  [32064/40000]\n","loss: 0.698409  [38464/40000]\n","Test Error: \n"," Accuracy: 40.6%, Avg loss: 0.705017 \n","\n","Epoch 2\n","-------------------------------\n","loss: 0.706709  [   64/40000]\n","loss: 0.699678  [ 6464/40000]\n","loss: 0.702723  [12864/40000]\n","loss: 0.695914  [19264/40000]\n","loss: 0.697385  [25664/40000]\n","loss: 0.695228  [32064/40000]\n","loss: 0.693248  [38464/40000]\n","Test Error: \n"," Accuracy: 59.4%, Avg loss: 0.692857 \n","\n","Epoch 3\n","-------------------------------\n","loss: 0.692809  [   64/40000]\n","loss: 0.690087  [ 6464/40000]\n","loss: 0.692772  [12864/40000]\n","loss: 0.689058  [19264/40000]\n","loss: 0.687965  [25664/40000]\n","loss: 0.685920  [32064/40000]\n","loss: 0.681187  [38464/40000]\n","Test Error: \n"," Accuracy: 59.4%, Avg loss: 0.685995 \n","\n","Epoch 4\n","-------------------------------\n","loss: 0.696755  [   64/40000]\n","loss: 0.688322  [ 6464/40000]\n","loss: 0.691238  [12864/40000]\n","loss: 0.693012  [19264/40000]\n","loss: 0.681392  [25664/40000]\n","loss: 0.687003  [32064/40000]\n","loss: 0.688975  [38464/40000]\n","Test Error: \n"," Accuracy: 59.4%, Avg loss: 0.682025 \n","\n","Epoch 5\n","-------------------------------\n","loss: 0.677475  [   64/40000]\n","loss: 0.686421  [ 6464/40000]\n","loss: 0.681148  [12864/40000]\n","loss: 0.694109  [19264/40000]\n","loss: 0.677819  [25664/40000]\n","loss: 0.674664  [32064/40000]\n","loss: 0.679868  [38464/40000]\n","Test Error: \n"," Accuracy: 59.4%, Avg loss: 0.679721 \n","\n","Done!\n"]}]},{"cell_type":"code","source":["X = torch.rand(64, 110, device=device)\n","logits = model(X)\n","pred_probab = nn.Softmax(dim=1)(logits)\n","y_pred = pred_probab.argmax(1)\n","print(f\"Predicted class: {y_pred}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yfmiMvngV4JH","executionInfo":{"status":"ok","timestamp":1677448113981,"user_tz":300,"elapsed":223,"user":{"displayName":"FrozenPeak","userId":"16767934579065722113"}},"outputId":"efb18b13-c314-4693-95f3-0b2ad0b6c1f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted class: tensor([1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n","        0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1])\n"]}]},{"cell_type":"code","source":["count = 0\n","\n","for i in range(len(testing_data)):\n","  if testing_data_results.iloc[i]==3:\n","    count+=1\n","\n","count/len(testing_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sYMPp8j5nRul","executionInfo":{"status":"ok","timestamp":1677448140029,"user_tz":300,"elapsed":220,"user":{"displayName":"FrozenPeak","userId":"16767934579065722113"}},"outputId":"d83280a4-707e-43cc-849f-a1107b5f2bce"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5940229885057471"]},"metadata":{},"execution_count":66}]},{"cell_type":"markdown","source":["LMAO, although the model doesn't seem to only produce democrats, it seems all the predictions made in the testing data was democrats and thus resulting in a 59.4% accuracy."],"metadata":{"id":"anKIpYVds5Xx"}},{"cell_type":"code","source":["torch.save(model, 'model.pth')"],"metadata":{"id":"5L5_-J0U6Usu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model = torch.load('model.pth')"],"metadata":{"id":"OSEPEaQqtgiv"},"execution_count":null,"outputs":[]}]}